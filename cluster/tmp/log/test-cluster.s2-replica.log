2022-03-28 07:41:23.526 [249] main/103/init.lua I> Using advertise_uri "localhost:3305"
2022-03-28 07:41:23.526 [249] main/103/init.lua I> Membership encryption enabled
2022-03-28 07:41:23.529 [249] main/103/init.lua I> Probe uri was successful
2022-03-28 07:41:23.530 [249] main/103/init.lua I> Membership BROADCAST sent to 127.0.0.1:3306
2022-03-28 07:41:23.531 [249] main/103/init.lua I> Membership BROADCAST sent to 172.27.255.255:3306
2022-03-28 07:41:23.532 [249] main/103/init.lua I> Membership BROADCAST sent to 127.0.0.1:3304
2022-03-28 07:41:23.533 [249] main/103/init.lua I> Membership BROADCAST sent to 172.27.255.255:3304
2022-03-28 07:41:23.534 [249] main/103/init.lua I> Membership BROADCAST sent to 127.0.0.1:3301
2022-03-28 07:41:23.534 [249] main/103/init.lua I> Membership BROADCAST sent to 172.27.255.255:3301
2022-03-28 07:41:23.535 [249] main/103/init.lua I> Membership BROADCAST sent to 127.0.0.1:3305
2022-03-28 07:41:23.536 [249] main/103/init.lua I> Membership BROADCAST sent to 172.27.255.255:3305
2022-03-28 07:41:23.546 [249] main/107/http/0.0.0.0:8085 I> started
2022-03-28 07:41:23.547 [249] main/103/init.lua I> Listening HTTP on 0.0.0.0:8085
2022-03-28 07:41:23.549 [249] main/108/console/unix/:/tmp/run/test-cluster.s2-replica.control I> started
2022-03-28 07:41:24.042 [249] main/103/init.lua I> "tuple.keydef" module is not found. Built-in "key_def" is used
2022-03-28 07:41:24.094 [249] main/103/init.lua I> "tuple.merger" module is not found. Built-in "merger" is used
2022-03-28 07:41:24.167 [249] main/109/remote_control/0.0.0.0:3305 I> started
2022-03-28 07:41:24.167 [249] main/103/init.lua I> Remote control bound to 0.0.0.0:3305
2022-03-28 07:41:24.168 [249] main/103/init.lua I> Remote control ready to accept connections
2022-03-28 07:41:24.168 [249] main/103/init.lua I> Instance state changed:  -> Unconfigured
2022-03-28 07:41:24.169 [249] main/103/init.lua I> Cartridge 2.7.3
2022-03-28 07:41:24.170 [249] main/103/init.lua I> server alias s2-replica
2022-03-28 07:41:24.170 [249] main/103/init.lua I> advertise uri localhost:3305
2022-03-28 07:41:24.171 [249] main/103/init.lua I> working directory /tmp/data/test-cluster.s2-replica
2022-03-28 07:41:24.171 [249] main C> entering the event loop
2022-03-28 07:41:34.269 [249] main/115/remote_control/127.0.0.1:44462 I> Instance state changed: Unconfigured -> BootstrappingBox
2022-03-28 07:41:34.270 [249] main/115/remote_control/127.0.0.1:44462 confapplier.lua:460 W> Calling box.cfg()...
2022-03-28 07:41:34.275 [249] main/115/remote_control/127.0.0.1:44462 C> Tarantool 2.8.3-83-ga3658df
2022-03-28 07:41:34.276 [249] main/115/remote_control/127.0.0.1:44462 C> log level 5
2022-03-28 07:41:34.276 [249] main/115/remote_control/127.0.0.1:44462 I> wal/engine cleanup is paused
2022-03-28 07:41:34.282 [249] main/115/remote_control/127.0.0.1:44462 I> mapping 268435456 bytes for memtx tuple arena...
2022-03-28 07:41:34.282 [249] main/115/remote_control/127.0.0.1:44462 I> Actual slab_alloc_factor calculated on the basis of desired slab_alloc_factor = 1.044274
2022-03-28 07:41:34.283 [249] main/115/remote_control/127.0.0.1:44462 I> mapping 134217728 bytes for vinyl tuple arena...
2022-03-28 07:41:34.303 [249] main/115/remote_control/127.0.0.1:44462 systemd.c:132 !> systemd: failed to send message: Connection refused
2022-03-28 07:41:34.307 [249] main/115/remote_control/127.0.0.1:44462 I> instance uuid c51bc266-d45b-4547-a6d2-5c77f439628b
2022-03-28 07:41:34.311 [249] main/116/remote_control/127.0.0.1:44462 I> Cartridge 2.7.3
2022-03-28 07:41:34.311 [249] main/116/remote_control/127.0.0.1:44462 I> server alias s2-replica
2022-03-28 07:41:34.314 [249] main/116/remote_control/127.0.0.1:44462 I> advertise uri localhost:3305
2022-03-28 07:41:34.316 [249] main/116/remote_control/127.0.0.1:44462 I> working directory /tmp/data/test-cluster.s2-replica
2022-03-28 07:41:34.319 [249] main/115/remote_control/127.0.0.1:44462 I> tx_binary: stopped
2022-03-28 07:41:34.322 [249] main/115/remote_control/127.0.0.1:44462 I> connecting to 1 replicas
2022-03-28 07:41:34.328 [249] main/123/applier/admin@localhost:3304 I> remote master 00000000-0000-0000-0000-000000000000 at 127.0.0.1:3304 running Tarantool 1.10.0
2022-03-28 07:41:34.362 [249] main/123/applier/admin@localhost:3304 I> can't connect to master
2022-03-28 07:41:34.362 [249] main/123/applier/admin@localhost:3304 coio.cc:359 !> SystemError unexpected EOF when reading from socket, called on fd 21, aka 127.0.0.1:52478, peer of 127.0.0.1:3304: Broken pipe
2022-03-28 07:41:34.362 [249] main/123/applier/admin@localhost:3304 I> will retry every 1.00 second
2022-03-28 07:41:35.363 [249] main/123/applier/admin@localhost:3304 I> remote master d7f4147f-0621-4967-b232-d44d72d59dde at 127.0.0.1:3304 running Tarantool 2.8.3
2022-03-28 07:41:35.364 [249] main/115/remote_control/127.0.0.1:44462 I> connected to 1 replicas
2022-03-28 07:41:35.365 [249] main/123/applier/admin@localhost:3304 I> authenticated
2022-03-28 07:41:35.365 [249] main/115/remote_control/127.0.0.1:44462 I> bootstrapping replica from d7f4147f-0621-4967-b232-d44d72d59dde at 127.0.0.1:3304
2022-03-28 07:41:35.412 [249] main/123/applier/admin@localhost:3304 I> cluster uuid eef0556e-a2b9-4edd-bb31-2506e2ddde0f
2022-03-28 07:41:35.419 [249] main/123/applier/admin@localhost:3304 I> assigned id 1 to replica d7f4147f-0621-4967-b232-d44d72d59dde
2022-03-28 07:41:35.420 [249] main/123/applier/admin@localhost:3304 I> initial data received
2022-03-28 07:41:35.420 [249] main/123/applier/admin@localhost:3304 I> assigned id 2 to replica c51bc266-d45b-4547-a6d2-5c77f439628b
2022-03-28 07:41:35.421 [249] main/123/applier/admin@localhost:3304 I> final data received
2022-03-28 07:41:35.427 [249] snapshot/101/main I> saving snapshot `/tmp/data/test-cluster.s2-replica/00000000000000000044.snap.inprogress'
2022-03-28 07:41:35.430 [249] snapshot/101/main I> done
2022-03-28 07:41:35.431 [249] main/115/remote_control/127.0.0.1:44462 systemd.c:132 !> systemd: failed to send message: Connection refused
2022-03-28 07:41:35.431 [249] main/115/remote_control/127.0.0.1:44462 I> ready to accept requests
2022-03-28 07:41:35.431 [249] main/115/remote_control/127.0.0.1:44462 I> synchronizing with 1 replicas
2022-03-28 07:41:35.432 [249] main/123/applier/admin@localhost:3304 I> subscribed
2022-03-28 07:41:35.432 [249] main/123/applier/admin@localhost:3304 I> remote vclock {1: 44} local vclock {1: 44}
2022-03-28 07:41:35.432 [249] main/123/applier/admin@localhost:3304 I> RAFT: message {term: 1, state: follower} from 1
2022-03-28 07:41:35.433 [249] main/127/applierw/admin@localhost:3304 C> leaving orphan mode
2022-03-28 07:41:35.433 [249] main/127/applierw/admin@localhost:3304 systemd.c:132 !> systemd: failed to send message: Connection refused
2022-03-28 07:41:35.434 [249] main/115/remote_control/127.0.0.1:44462 I> replica set sync complete
2022-03-28 07:41:35.434 [249] main/115/remote_control/127.0.0.1:44462 C> leaving orphan mode
2022-03-28 07:41:35.434 [249] main/115/remote_control/127.0.0.1:44462 systemd.c:132 !> systemd: failed to send message: Connection refused
2022-03-28 07:41:35.434 [249] main/115/remote_control/127.0.0.1:44462 I> set 'custom_proc_title' configuration option to "test-cluster@s2-replica"
2022-03-28 07:41:35.435 [249] main/115/remote_control/127.0.0.1:44462 I> set 'log_level' configuration option to 5
2022-03-28 07:41:35.435 [249] main/118/checkpoint_daemon I> scheduled next checkpoint for Mon Mar 28 08:52:24 2022
2022-03-28 07:41:35.443 [249] main/115/remote_control/127.0.0.1:44462 I> set 'replication' configuration option to ["admin@localhost:3304"]
2022-03-28 07:41:35.443 [249] main/115/remote_control/127.0.0.1:44462 I> set 'instance_uuid' configuration option to "c51bc266-d45b-4547-a6d2-5c77f439628b"
2022-03-28 07:41:35.448 [249] main/115/remote_control/127.0.0.1:44462 I> set 'read_only' configuration option to true
2022-03-28 07:41:35.449 [249] main/115/remote_control/127.0.0.1:44462 I> set 'log_format' configuration option to "plain"
2022-03-28 07:41:35.449 [249] main/115/remote_control/127.0.0.1:44462 I> set 'replicaset_uuid' configuration option to "eef0556e-a2b9-4edd-bb31-2506e2ddde0f"
2022-03-28 07:41:35.453 [249] main/115/remote_control/127.0.0.1:44462 I> Making sure user "admin" exists...
2022-03-28 07:41:35.453 [249] main/115/remote_control/127.0.0.1:44462 I> Granting replication permissions to "admin"...
2022-03-28 07:41:35.454 [249] main/115/remote_control/127.0.0.1:44462 I> Remote control stopped
2022-03-28 07:41:35.454 [249] main/109/remote_control/0.0.0.0:3305 I> stopped
2022-03-28 07:41:35.454 [249] main/115/remote_control/127.0.0.1:44462 I> tx_binary: stopped
2022-03-28 07:41:35.454 [249] main/115/remote_control/127.0.0.1:44462 I> tx_binary: bound to 0.0.0.0:3305
2022-03-28 07:41:35.455 [249] main/115/remote_control/127.0.0.1:44462 I> set 'listen' configuration option to "3305"
2022-03-28 07:41:35.455 [249] main/115/remote_control/127.0.0.1:44462 I> dropping fd 21, aka 127.0.0.1:3305, peer 127.0.0.1:44484
2022-03-28 07:41:35.456 [249] main/115/remote_control/127.0.0.1:44462 I> Instance state changed: BootstrappingBox -> ConnectingFullmesh
2022-03-28 07:41:35.456 [249] main/115/remote_control/127.0.0.1:44462 I> connecting to 2 replicas
2022-03-28 07:41:35.461 [249] main/136/applier/admin@localhost:3304 I> remote master d7f4147f-0621-4967-b232-d44d72d59dde at 127.0.0.1:3304 running Tarantool 2.8.3
2022-03-28 07:41:35.465 [249] main/137/applier/admin@localhost:3305 I> remote master c51bc266-d45b-4547-a6d2-5c77f439628b at 127.0.0.1:3305 running Tarantool 2.8.3
2022-03-28 07:41:35.465 [249] main/115/remote_control/127.0.0.1:44462 I> connected to 2 replicas
2022-03-28 07:41:35.466 [249] main/115/remote_control/127.0.0.1:44462 I> synchronizing with 2 replicas
2022-03-28 07:41:35.466 [249] main/137/applier/admin@localhost:3305 C> leaving orphan mode
2022-03-28 07:41:35.467 [249] main/137/applier/admin@localhost:3305 systemd.c:132 !> systemd: failed to send message: Connection refused
2022-03-28 07:41:35.467 [249] main/115/remote_control/127.0.0.1:44462 I> replica set sync complete
2022-03-28 07:41:35.467 [249] main/115/remote_control/127.0.0.1:44462 C> leaving orphan mode
2022-03-28 07:41:35.468 [249] main/115/remote_control/127.0.0.1:44462 systemd.c:132 !> systemd: failed to send message: Connection refused
2022-03-28 07:41:35.468 [249] main/115/remote_control/127.0.0.1:44462 I> set 'replication' configuration option to ["admin@localhost:3304","admin@localhost:3305"]
2022-03-28 07:41:35.468 [249] main/115/remote_control/127.0.0.1:44462 I> Instance state changed: ConnectingFullmesh -> BoxConfigured
2022-03-28 07:41:35.469 [249] main/115/remote_control/127.0.0.1:44462 I> Instance state changed: BoxConfigured -> ConfiguringRoles
2022-03-28 07:41:35.469 [249] main/115/remote_control/127.0.0.1:44462 C> leaving orphan mode
2022-03-28 07:41:35.469 [249] main/115/remote_control/127.0.0.1:44462 systemd.c:132 !> systemd: failed to send message: Connection refused
2022-03-28 07:41:35.470 [249] main/115/remote_control/127.0.0.1:44462 I> set 'replication_connect_quorum' configuration option to 0
2022-03-28 07:41:35.470 [249] main/115/remote_control/127.0.0.1:44462 I> Failover disabled
2022-03-28 07:41:35.470 [249] main/115/remote_control/127.0.0.1:44462 I> Replicaset dca7d0e4-2d29-4f00-ad2f-b15461f9273b: new leader 7151d922-1035-49c3-8da8-e99c8406223c ("localhost:3301"), was nil
2022-03-28 07:41:35.471 [249] main/115/remote_control/127.0.0.1:44462 I> Replicaset f9ac02c4-497c-40d4-890d-3b868c37caa1: new leader 61aa4e22-fd63-43d2-bc56-ea84f3d76cd2 ("localhost:3302"), was nil
2022-03-28 07:41:35.471 [249] main/115/remote_control/127.0.0.1:44462 I> Replicaset eef0556e-a2b9-4edd-bb31-2506e2ddde0f (me): new leader d7f4147f-0621-4967-b232-d44d72d59dde ("localhost:3304"), was nil
2022-03-28 07:41:35.472 [249] main/115/remote_control/127.0.0.1:44462 I> Reconfiguring vshard.storage...
2022-03-28 07:41:35.472 [249] main/115/remote_control/127.0.0.1:44462 I> Starting configuration of replica c51bc266-d45b-4547-a6d2-5c77f439628b
2022-03-28 07:41:35.472 [249] main/115/remote_control/127.0.0.1:44462 I> connecting to 2 replicas
2022-03-28 07:41:35.473 [249] main/115/remote_control/127.0.0.1:44462 C> failed to connect to 2 out of 2 replicas
2022-03-28 07:41:35.473 [249] main/115/remote_control/127.0.0.1:44462 C> leaving orphan mode
2022-03-28 07:41:35.473 [249] main/115/remote_control/127.0.0.1:44462 systemd.c:132 !> systemd: failed to send message: Connection refused
2022-03-28 07:41:35.474 [249] main/115/remote_control/127.0.0.1:44462 I> set 'replication' configuration option to ["admin@localhost:3305","admin@localhost:3304"]
2022-03-28 07:41:35.474 [249] main/115/remote_control/127.0.0.1:44462 I> Box has been configured
2022-03-28 07:41:35.479 [249] main/115/remote_control/127.0.0.1:44462 I> Roles configuration finished
2022-03-28 07:41:35.479 [249] main/115/remote_control/127.0.0.1:44462 I> Instance state changed: ConfiguringRoles -> RolesConfigured
2022-03-28 07:41:35.480 [249] main/110/remote_control/127.0.0.1:44462 utils.c:449 E> LuajitError: builtin/socket.lua:88: attempt to use closed socket
2022-03-28 07:41:35.480 [249] main/141/applier/admin@localhost:3305 I> remote master c51bc266-d45b-4547-a6d2-5c77f439628b at 127.0.0.1:3305 running Tarantool 2.8.3
2022-03-28 07:41:35.480 [249] main/140/applier/admin@localhost:3304 I> remote master d7f4147f-0621-4967-b232-d44d72d59dde at 127.0.0.1:3304 running Tarantool 2.8.3
2022-03-28 07:41:35.481 [249] main/141/applier/admin@localhost:3305 C> leaving orphan mode
2022-03-28 07:41:35.481 [249] main/141/applier/admin@localhost:3305 systemd.c:132 !> systemd: failed to send message: Connection refused
2022-03-28 07:41:35.482 [249] main/140/applier/admin@localhost:3304 I> authenticated
2022-03-28 07:41:35.482 [249] main/140/applier/admin@localhost:3304 I> subscribed
2022-03-28 07:41:35.482 [249] main/140/applier/admin@localhost:3304 I> remote vclock {1: 44} local vclock {1: 44}
2022-03-28 07:41:35.483 [249] main/140/applier/admin@localhost:3304 I> RAFT: message {term: 1, state: follower} from 1
2022-03-28 07:41:35.484 [249] main/142/applierw/admin@localhost:3304 C> leaving orphan mode
2022-03-28 07:41:35.484 [249] main/142/applierw/admin@localhost:3304 systemd.c:132 !> systemd: failed to send message: Connection refused
2022-03-28 07:41:35.499 [249] main/122/main I> Backup of active config created: "/tmp/data/test-cluster.s2-replica/config.backup"
2022-03-28 07:41:35.500 [249] main/122/main I> Instance state changed: RolesConfigured -> ConfiguringRoles
2022-03-28 07:41:35.500 [249] main/122/main I> connecting to 2 replicas
2022-03-28 07:41:35.500 [249] main/122/main C> failed to connect to 2 out of 2 replicas
2022-03-28 07:41:35.501 [249] main/122/main C> leaving orphan mode
2022-03-28 07:41:35.501 [249] main/122/main systemd.c:132 !> systemd: failed to send message: Connection refused
2022-03-28 07:41:35.501 [249] main/122/main I> set 'replication' configuration option to ["admin@localhost:3304","admin@localhost:3305"]
2022-03-28 07:41:35.502 [249] main/122/main I> Failover disabled
2022-03-28 07:41:35.503 [249] main/122/main I> Roles configuration finished
2022-03-28 07:41:35.503 [249] main/122/main I> Instance state changed: ConfiguringRoles -> RolesConfigured
2022-03-28 07:41:35.504 [249] main/146/applier/admin@localhost:3304 I> remote master d7f4147f-0621-4967-b232-d44d72d59dde at 127.0.0.1:3304 running Tarantool 2.8.3
2022-03-28 07:41:35.504 [249] main/145/applier/admin@localhost:3305 I> remote master c51bc266-d45b-4547-a6d2-5c77f439628b at 127.0.0.1:3305 running Tarantool 2.8.3
2022-03-28 07:41:35.505 [249] main/145/applier/admin@localhost:3305 C> leaving orphan mode
2022-03-28 07:41:35.505 [249] main/145/applier/admin@localhost:3305 systemd.c:132 !> systemd: failed to send message: Connection refused
2022-03-28 07:41:35.505 [249] main/146/applier/admin@localhost:3304 I> authenticated
2022-03-28 07:41:35.506 [249] main/146/applier/admin@localhost:3304 I> can't join/subscribe
2022-03-28 07:41:35.506 [249] main/146/applier/admin@localhost:3304 box.cc:2917 E> ER_CFG: Incorrect value for option 'replication': duplicate connection with the same replica UUID
2022-03-28 07:41:35.506 [249] main/146/applier/admin@localhost:3304 I> will retry every 1.00 second
2022-03-28 07:41:35.507 [249] main/122/main I> subscribed replica d7f4147f-0621-4967-b232-d44d72d59dde at fd 25, aka 127.0.0.1:3305, peer of 127.0.0.1:44540
2022-03-28 07:41:35.507 [249] main/122/main I> remote vclock {1: 44} local vclock {1: 44}
2022-03-28 07:41:35.507 [249] main/117/gc I> wal/engine cleanup is resumed
2022-03-28 07:41:35.616 [249] main/147/main I> Backup of active config created: "/tmp/data/test-cluster.s2-replica/config.backup"
2022-03-28 07:41:35.617 [249] main/147/main I> Instance state changed: RolesConfigured -> ConfiguringRoles
2022-03-28 07:41:35.617 [249] main/147/main I> Failover disabled
2022-03-28 07:41:35.618 [249] main/147/main I> Roles configuration finished
2022-03-28 07:41:35.619 [249] main/147/main I> Instance state changed: ConfiguringRoles -> RolesConfigured
2022-03-28 07:41:36.510 [249] main/146/applier/admin@localhost:3304 I> authenticated
2022-03-28 07:41:36.512 [249] main/146/applier/admin@localhost:3304 I> subscribed
2022-03-28 07:41:36.512 [249] main/146/applier/admin@localhost:3304 I> remote vclock {1: 15044} local vclock {1: 44}
2022-03-28 07:41:36.513 [249] main/146/applier/admin@localhost:3304 I> RAFT: message {term: 1, state: follower} from 1
2022-03-28 07:41:36.527 [249] relay/127.0.0.1:44540/101/main I> recover from `/tmp/data/test-cluster.s2-replica/00000000000000000044.xlog'
2022-03-28 07:41:36.553 [249] main/148/applierw/admin@localhost:3304 C> leaving orphan mode
2022-03-28 07:41:36.554 [249] main/148/applierw/admin@localhost:3304 systemd.c:132 !> systemd: failed to send message: Connection refused
2022-03-28 07:41:45.708 [249] main/151/main I> Schema validation skipped because the instance isn't a leader
2022-03-28 07:41:45.716 [249] main/151/main I> Backup of active config created: "/tmp/data/test-cluster.s2-replica/config.backup"
2022-03-28 07:41:45.716 [249] main/151/main I> Instance state changed: RolesConfigured -> ConfiguringRoles
2022-03-28 07:41:45.717 [249] main/151/main I> Failover disabled
2022-03-28 07:41:45.718 [249] main/151/main I> Roles configuration finished
2022-03-28 07:41:45.718 [249] main/151/main I> Instance state changed: ConfiguringRoles -> RolesConfigured
2022-03-28 07:41:45.779 [249] main C> got signal 15 - Terminated
2022-03-28 07:41:45.780 [249] main/152/trigger_fiber0 I> Starting reconfiguration of replica c51bc266-d45b-4547-a6d2-5c77f439628b
2022-03-28 07:41:45.780 [249] main/152/trigger_fiber0 I> Box has been configured
2022-03-28 07:41:45.780 [249] main/153/lua I> Old replicaset and replica objects are outdated.
2022-03-28 07:41:45.796 [249] main I> tx_binary: stopped
